{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "서론\n",
    "- feed forward NN\n",
    "  - 흐름이 단방향인 신경망\n",
    "  - 시계열 데이터를 잘 다루지 못한다는 단점\n",
    "  - 시계열 데이터의 성질을 충분히 학습할 수 없다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 확률과 언어 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.1 word2vec을 확률 관점에서 바라보다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.2 언어모델\n",
    "- 언어모델은 단어 나열에 확률을 부여한다.\n",
    "\n",
    "<img src=\"../../../data/deep_learning_2_images/fig 5-4.png\" width=\"500\">\n",
    "\n",
    "- 동시확률은 사후 확률의 총곱\n",
    "- 사후 확률은 타깃 단어보다 왼쪽에 있는 모든 단어를 맥락으로 했을 때의 확률"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2 RNN이란\n",
    "- RNN , Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.1 순환하는 신경망\n",
    "- 순환하기 위해서는 닫힌 경로가 필요하다.\n",
    "\n",
    "<img src=\"../../../data/deep_learning_2_images/fig 5-6.png\" width=\"200\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.2 순환 구조 펼치기\n",
    "\n",
    "<img src=\"../../../data/deep_learning_2_images/fig 5-8.png\" width=\"500\">\n",
    "\n",
    "- $h_t = tanh(h_{t-1}W_h+x_tW_x+b)$\n",
    "- h라는 상태를 가진다.\n",
    "- $h_t$를 은닉상태(hidden state) 혹은 은닉상태벡터(hidden state vector)라고 한다.\n",
    "\n",
    "<img src=\"../../../data/deep_learning_2_images/fig 5-9.png\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.3 BPTT\n",
    "<img src=\"../../../data/deep_learning_2_images/fig 5-10.png\" width=\"500\">\n",
    "\n",
    "- Backpropagation Throuhg Time\n",
    "- 긴 시계열 데이터를 학습할 때의 문제\n",
    "  - BPTT가 소비하는 컴퓨팅 자원도 증가하기 때문에\n",
    "  - 역전파 시의 기울기가 불안정해진다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.4 Truncated BPTT\n",
    "- 신경망을 적당한 길이로 끊는다.\n",
    "- 작은 신경망 여러 개로 만든다.\n",
    "- 역전파의 연결만 끊는다. 순전파의 연결은 그대로\n",
    "\n",
    "<img src=\"../../../data/deep_learning_2_images/fig 5-11.png\" width=\"500\">\n",
    "\n",
    "- 반드시 기억할 점은 역전파의 연결은 끊어지지만 순전파의 연결은 끊어지지 않는다는 점\n",
    "- 데이터를 순서대로 sequential 입력해야 한다.\n",
    "\n",
    "<img src=\"../../../data/deep_learning_2_images/fig 5-12.png\" width=\"300\">\n",
    "<img src=\"../../../data/deep_learning_2_images/fig 5-13.png\" width=\"300\">\n",
    "\n",
    "- 순전파는 이어지고, 역전파는 블록 단위로 진행됨\n",
    "\n",
    "<img src=\"../../../data/deep_learning_2_images/fig 5-14.png\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.5 Truncated BPTT의 미니배치 학습\n",
    "- 데이터를 주는 시작 위치를 각 미니배치의 시작 위치로 옮겨줘야 한다.\n",
    "\n",
    "<img src=\"../../../data/deep_learning_2_images/fig 5-15.png\" width=\"500\">\n",
    "\n",
    "- 미니배치 학습을 수행할 때는 각 미니배치의 시작 위치를 오프셋으로 옮겨준 후 순서대로 제공하면 됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3 RNN 구현\n",
    "\n",
    "<img src=\"../../../data/deep_learning_2_images/fig 5-17.png\" width=\"550\">\n",
    "\n",
    "- Time RNN 계층 내에서 한 단계의 작업을 수행하는 계층을 'RNN 계층'이라 함.\n",
    "- T개 단계분의 작업을 한꺼번에 처리하는 계층을 'Time RNN 계층'이라 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3.1 RNN 계층 구현\n",
    "<img src=\"../../../data/deep_learning_2_images/e 5-10.png\" width=\"300\">\n",
    "\n",
    "- 미니배치로 처리\n",
    "\n",
    "<img src=\"../../../data/deep_learning_2_images/fig 5-18.png\" width=\"300\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forward\n",
    "\n",
    "<img src=\"../../../data/deep_learning_2_images/fig 5-19.png\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class RNN:\n",
    "  def __init__(self, Wx, Wh, b):\n",
    "    self.params = [Wx, Wh, b] # N x H, H x H, N x 1\n",
    "    self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "    self.cache = None\n",
    "    \n",
    "  def forward(self, x, h_prev):\n",
    "    Wx, Wh, b = self.params\n",
    "    t = np.matmul(h_prev, Wh) + np.matmul(x, Wx) + b\n",
    "    h_next = np.tanh(t)\n",
    "    \n",
    "    self.cache = (x, h_prev, h_next)\n",
    "    \n",
    "    return h_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "backward\n",
    "\n",
    "<img src=\"../../../data/deep_learning_2_images/fig 5-20.png\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(self, dh_next):\n",
    "  Wx, Wh, b = self.params\n",
    "  x, h_prev, h_next = self.cache\n",
    "  \n",
    "  dt = dh_next * (1 - h_next ** 2)\n",
    "  db = np.sum(dt, axis=0)\n",
    "  dWh = np.matmul(h_prev.T, dt)\n",
    "  dh_prev = np.matmul(dt, Wh.T)\n",
    "  dWx = np.matmul(x.T, dt)\n",
    "  dx = np.matmul(dt, Wx.T)\n",
    "  \n",
    "  self.grads[0][...] = dWx\n",
    "  self.grads[1][...] = dWh\n",
    "  self.grads[2][...] = db\n",
    "  \n",
    "  return dx, dh_prev\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3.2 Time RNN 계층 구현\n",
    "\n",
    "<img src=\"../../../data/deep_learning_2_images/fig 5-21.png\" width=\"500\">\n",
    "<img src=\"../../../data/deep_learning_2_images/fig 5-22.png\" width=\"500\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeRNN:\n",
    "  def __init__(self, Wx, Wh, b, stateful=False):\n",
    "    self.params = [Wx, Wh, b]\n",
    "    self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "    self.layers = None\n",
    "    \n",
    "    self.h, self.dh = None, None\n",
    "    self.stateful = stateful # 은닉상태를 인계 받을지 여부\n",
    "    \n",
    "  def forward(self, xs):\n",
    "    Wx, Wh, b = self.params\n",
    "    N, T, D = xs.shape\n",
    "    D, H = Wx.shape\n",
    "    \n",
    "    self.layers = []\n",
    "    hs = np.empty((N, T, H), dtype='f')\n",
    "    \n",
    "    if not self.stateful or self.h is None:\n",
    "      self.h = np.zeros((N, H), dtype='f') # 영행렬로 초기화\n",
    "      \n",
    "    for t in range(T):\n",
    "      layer = RNN(*self.params)\n",
    "      self.h = layer.forward(xs[:, t, :], self.h)\n",
    "      hs[:, t, :] = self.h\n",
    "      self.layers.append(layer)\n",
    "      \n",
    "    return hs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time RNN 계층의 역전파\n",
    "\n",
    "<img src=\"../../../data/deep_learning_2_images/fig 5-23.png\" width=\"500\">\n",
    "<img src=\"../../../data/deep_learning_2_images/fig 5-24.png\" width=\"500\">\n",
    "\n",
    "- 순전파에서는 출력이 2개로 분기됨. \n",
    "- 따라서 역전파에서는 각 기울기가 합산되어 전해짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(self, dhs):\n",
    "  Wx, Wh, b = self.params\n",
    "  N, T, H = dhs.shape\n",
    "  D, H = Wx.shape\n",
    "  \n",
    "  dxs = np.empty((N, T, D), dtype='f')\n",
    "  dh = 0\n",
    "  grads = [0, 0, 0]\n",
    "  for t in reversed(range(T)):\n",
    "    layer = self.layers[t]\n",
    "    dx, dh = layer.backward(dhs[:, t, :] + dh) # 합산된 기울기 ( 위로 올라간거 + 앞에로 간거랑)\n",
    "    dxs[:, t, :] = dx\n",
    "    \n",
    "    for i, grad in enumerate(layer.grads):\n",
    "      grads[i] += grad\n",
    "      \n",
    "  for i, grad in enumerate(grads):\n",
    "    self.grads[i][...] = grad\n",
    "  self.dh = dh\n",
    "  \n",
    "  return dxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.4 시계열 데이터 처리 계층 구현\n",
    "- RNN을 이용해서 '언어 모델'을 구현하는 것\n",
    "- 시계열 데이터를 처리하는 계층을 몇 개 더 추가\n",
    "- RNNLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4.1 RNNLM의 전체그림\n",
    "<img src=\"../../../data/deep_learning_2_images/fig 5-25.png\" width=\"500\">\n",
    "\n",
    "- Embedding : 단어 ID를 단어의 분산표현으로 변환\n",
    "\n",
    "<img src=\"../../../data/deep_learning_2_images/fig 5-26.png\" width=\"500\">\n",
    "\n",
    "- RNN 계층은 \"you say\"라는 맥락을 '기억'하고 있다는 사실.\n",
    "- RNN은 \"you say\"라는 과거의 정보를 응집된 은닉 상태 벡터로 저장해두고 있다.\n",
    "- RNNLM은 지금까지 입력된 단어를 기억하고 그것을 바탕으로 다음에 출현할 단어를 예측\n",
    "- RNN 계층이 과거에서 현재로 데이터를 계속 흘려보내줌으로써 과거의 정보를 인코딩해 저장(기억)할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4.2 Time 계층 구현\n",
    "- Time RNN, Time Embedding, Time Affine\n",
    "\n",
    "<img src=\"../../../data/deep_learning_2_images/fig 5-27.png\" width=\"500\">\n",
    "\n",
    "- Time Affine\n",
    "  - 단순히 Affine 계층 T개를 이용하는 방식 대신 행렬 계산으로 한꺼번에 처리하는, 효율 좋은 방식으로 구현\n",
    "  \n",
    "<img src=\"../../../data/deep_learning_2_images/fig 5-28.png\" width=\"500\">\n",
    "\n",
    "\n",
    "- Time Softmax with Loss \n",
    "  - $x_0 , x_1$ 등의 데이터는 아래층에서부터 전해지는 '점수'를 나타냄\n",
    "  - $t_0, t_1$ 등의 데이터는 정답 레이블\n",
    "\n",
    "<img src=\"../../../data/deep_learning_2_images/fig 5-29.png\" width=\"500\">\n",
    "<img src=\"../../../data/deep_learning_2_images/e 5-11.png\" width=\"300\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.5 RNNLM 학습과 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5.1 RNNLM 구현\n",
    "\n",
    "<img src=\"../../../data/deep_learning_2_images/fig 5-30.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../modules/Part2/')\n",
    "import numpy as np\n",
    "from common.time_layers import *\n",
    "\n",
    "class SimpleRnnlm:\n",
    "  def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "    V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "    rn = np.random.randn\n",
    "    \n",
    "    # 가중치 초기화\n",
    "    embed_W = (rn(V, D) / 100).astype('f')\n",
    "    rnn_Wx = (rn(D, H) / np.sqrt(D)).astype('f')\n",
    "    rnn_Wh = (rn(H, H) / np.sqrt(H)).astype('f')\n",
    "    rnn_b = np.zeros(H).astye('f')\n",
    "    affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "    affine_b = np.zeros(H).astye('f')\n",
    "    \n",
    "    # 계층생성\n",
    "    self.layers = [\n",
    "      TimeEmbedding(embed_W),\n",
    "      TimeRNN(rnn_Wx, rnn_Wh, rnn_b, stateful=True),\n",
    "      TimeAffine(affine_W, affine_b)\n",
    "    ]\n",
    "    self.loss_layer = TimeSoftmaxWithLoss()\n",
    "    self.rnn_layer = self.layers[1]\n",
    "    \n",
    "    # 모든 가중치와 기울기를 리스트에 모은다.\n",
    "    self.params, self.grads = [], []\n",
    "    for layer in self.layers:\n",
    "      self.params += layer.params\n",
    "      self.grads += layer.grads\n",
    "      \n",
    "  def forward(self, xs, ts):\n",
    "    for layer in self.layers:\n",
    "      xs = layer.forward(xs)\n",
    "      \n",
    "    loss = self.loss_layer.forward(xs, ts)\n",
    "    return loss\n",
    "  \n",
    "  def backward(self, dout=1):\n",
    "    dout = self.loss_layer.backward(dout)\n",
    "    for layer in reversed(self.layers):\n",
    "      dout = layer.backward(dout)\n",
    "      \n",
    "    return dout\n",
    "  \n",
    "  def reset_state(self):\n",
    "    self.rnn_layer.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5.2 언어 모델의 평가\n",
    "- 언어모델은 과거 단어로부터 다음에 출현할 단어의 확률분포를 출력\n",
    "- 퍼플렉서티 perplxity , 혼란도\n",
    "  - 확률의 역수\n",
    "  - 작을수록 좋음\n",
    "  - 분기 수 , number of branches\n",
    "  - 정보이론 분야에서는 퍼플렉서티를 기하평균 분기 수라고도 한다.\n",
    "\n",
    "<img src=\"../../../data/deep_learning_2_images/e 5-12.png\" width=\"200\">\n",
    "<img src=\"../../../data/deep_learning_2_images/e 5-13.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5.3 RNNLM의 학습코드\n",
    "- PTB 데이터셋\n",
    "- 이번에 구현한 RNNLM은 PTB 데이터셋 전부를 대상으로 학습하면 전혀 좋은 결과를 낼 수 없다.\n",
    "- 처음 1000개 단어만 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../modules/Part2/')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from common.optimizer import SGD\n",
    "from dataset import ptb\n",
    "from simple_rnnlm import SimpleRnnlm\n",
    "\n",
    "# hyperparameter\n",
    "batch_size = 10\n",
    "word2vec_size = 100\n",
    "hidden_size = 100\n",
    "time_size = 5\n",
    "lr = 0.1\n",
    "max_epoch = 100\n",
    "\n",
    "# read train data ([:1000])\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_size = 1000\n",
    "corpus = corpus[:1000]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]\n",
    "data_size = len(xs)\n",
    "print(f\"말뭉치 크기: {corpus_size}, 어휘 수: {vocab_size}\")\n",
    "\n",
    "max_iters = data_size // (batch_size * time_size) # 1000 // (10 * 5) -> 20\n",
    "time_idx = 0\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "ppl_list = []\n",
    "\n",
    "# create model\n",
    "model = SimpleRnnlm(vocab_size, word2vec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "\n",
    "# 각 미니배치에서 샘플을 읽기 시작, 시작위치를 계산\n",
    "jump = (corpus_size - 1) // batch_size # 1000 // 10 -> 100\n",
    "offsets = [i * jump for i in range(batch_size)] # [0, 100, 200, ..., 900, 1000]\n",
    "\n",
    "for epoch in range(max_epoch): # [0, ..., 100]\n",
    "  for iter in range(max_iters): # [0, ..., 20]\n",
    "    # 미니배치 획득\n",
    "    batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "    batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "    for t in range(time_size):\n",
    "      for i, offset in enumerate(offsets):\n",
    "        batch_x[i, t] = xs[(offset + time_idx) % data_size]\n",
    "        batch_t[i, t] = ts[(offset + time_idx) % data_size]\n",
    "      time_idx += 1\n",
    "      \n",
    "      \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLFS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
