{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def preprocess(text):\n",
    "  text = text.lower()\n",
    "  text = text.replace('.', ' .')\n",
    "  \n",
    "  words = text.split(' ')\n",
    "  \n",
    "  word_to_id = {}\n",
    "  id_to_word = {}\n",
    "  for word in words:\n",
    "    if word not in word_to_id:\n",
    "      new_id = len(word_to_id)\n",
    "      word_to_id[word] = new_id\n",
    "      id_to_word[new_id] = word\n",
    "      \n",
    "  corpus = np.array([word_to_id[w] for w in words])\n",
    "  return corpus, word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 1, 5]),\n",
       " {'you': 0, 'say': 1, 'goodby': 2, 'and': 3, 'i': 4, 'hello': 5},\n",
       " {0: 'you', 1: 'say', 2: 'goodby', 3: 'and', 4: 'i', 5: 'hello'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"You say goodby and I say hello\"\n",
    "preprocess(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분산표현 (distributional representation)\n",
    "- 단어의 의미를 정확하게 파악할 수 있는 벡터 표현\n",
    "- 단어를 고정 길이의 밀집벡터로 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분포가설 (distributional hypothesis)\n",
    "- 단어의 의미는 주변 단어에 의해 형성된다.\n",
    "- 단어 자체에는 의미가 없고, 그 단어가 사용된 '맥락'이 의미를 형성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "통계기반 기법 \n",
    "- 주위에 어떤 단어가 몇 벙니나 등장하는지를 집계하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동시발생 행렬 (co-occurence matrix)\n",
    "- 모든 단어에 대해 동시 발생하는 단어를 표에 정리한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_co_matrix(corpus, vocab_size, window_size=1):\n",
    "  corpus_size = len(corpus)\n",
    "  co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
    "  \n",
    "  for idx, word_id in enumerate(corpus):\n",
    "    for i in range(1, window_size + 1):\n",
    "      left_idx = idx - 1\n",
    "      right_idx = idx + 1\n",
    "      \n",
    "      if left_idx >= 0:\n",
    "        left_word_id = corpus[left_idx]\n",
    "        co_matrix[word_id, left_word_id] += 1\n",
    "        \n",
    "      if right_idx < corpus_size:\n",
    "        right_word_id = corpus[right_idx]\n",
    "        co_matrix[word_id, right_word_id] += 1\n",
    "        \n",
    "  return co_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(x, y, eps=1e-8):\n",
    "  nx = x / np.sqrt(np.sum(x ** 2) + eps)\n",
    "  ny = y / np.sqrt(np.sum(y ** 2) + eps)\n",
    "  return np.dot(nx, ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071067758832467\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../modules/Part2/')\n",
    "from common.utils import preprocess, create_co_matrix, cos_similarity\n",
    "\n",
    "text = \"You say goodbye and I say hello\"\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "c0 = C[word_to_id['you']]\n",
    "c1 = C[word_to_id['i']]\n",
    "\n",
    "print(cos_similarity(c0, c1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(query, word_to_id, id_to_word, word_matrix, top=5):\n",
    "  if query not in word_to_id:\n",
    "    print('{query}를 찾을 수 없습니다.')\n",
    "    return\n",
    "  \n",
    "  print(f'\\n [{query}]')\n",
    "  query_id = word_to_id[query]\n",
    "  query_vec = word_matrix[query_id]\n",
    "  \n",
    "  vocab_size = len(id_to_word)\n",
    "  similarity = np.zeros(vocab_size)\n",
    "  for i in range(vocab_size):\n",
    "    similarity[i] = cos_similarity(word_matrix[i], query_vec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLFS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
